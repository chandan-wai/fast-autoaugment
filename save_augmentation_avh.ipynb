{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ubuntu/fast-autoaugment')\n",
    "import torch\n",
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from FastAutoAugment.networks import get_model\n",
    "from theconf import Config as C\n",
    "import random\n",
    "import copy\n",
    "from torchvision.transforms import transforms\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from FastAutoAugment.datasets import CIFAR10_mod \n",
    "from FastAutoAugment.metrics import accuracy\n",
    "from FastAutoAugment.hardness_measures import AVH\n",
    "from FastAutoAugment.augmentations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = C('/home/ubuntu/fast-autoaugment/confs/test.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(C.get()['model'], 10, local_rank=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If trained model is needed. Specify the save_path of the required run.\n",
    "save_path = '/efs-cotton/outputs/fast-autoaugment/confs/hardnessaware/wresnet28x10_rcifar-AA-rerun3/test.pth'\n",
    "data = torch.load(save_path)\n",
    "key = 'model' if 'model' in data else 'state_dict'\n",
    "\n",
    "if 'epoch' not in data:\n",
    "    model.load_state_dict(data)\n",
    "else:\n",
    "    if not isinstance(model, (DataParallel, DistributedDataParallel)):\n",
    "        model.load_state_dict({k.replace('module.', ''): v for k, v in data[key].items()})\n",
    "    else:\n",
    "        model.load_state_dict({k if 'module.' in k else 'module.'+k: v for k, v in data[key].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'loss': 0.43232580375671387,\n",
       "  'top1': 0.96325,\n",
       "  'top5': 0.99775,\n",
       "  'lr': 0.0006155829702431171},\n",
       " 'valid': {'loss': 0.0, 'top1': 0.0, 'top5': 0.0},\n",
       " 'test': {'loss': 0.5973012451648713, 'top1': 0.8451, 'top5': 0.9913}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {\"Rotate30+Solarize200\": [(\"Rotate\", 1, 30), (\"Solarize\", 1, 200)],\n",
    "          \"Rotate30+Solarize100\": [(\"Rotate\", 1, 30), (\"Solarize\", 1, 100)],\n",
    "          \"Rotate30+Solarize50\": [(\"Rotate\", 1, 30), (\"Solarize\", 1, 50)],\n",
    "          \"Rotate30+Contrast0.1\": [(\"Rotate\", 1, 30), (\"Contrast\", 1, 0.1)],\n",
    "          \"Contrast0.1\": [(\"Contrast\", 1, 0.1)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentation2(object):\n",
    "    def __init__(self, policies):\n",
    "        self.policies = policies\n",
    "\n",
    "    def __call__(self, img, hardness_score=None):\n",
    "        for name, pr, level in self.policies:\n",
    "            if random.random() > pr:\n",
    "                continue\n",
    "#             if level == 'random':\n",
    "#                 level = random.choice(range(10))*0.1\n",
    "            img = apply_augment_direct(img, name, level)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CIFAR_MEAN, _CIFAR_STD = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "dataroot = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "no_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "        ])\n",
    "basic_dataset = CIFAR10_mod(root=dataroot, train=True, download=True, transform=no_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_transforms = {}\n",
    "for key, value in policy.items():\n",
    "    transform = copy.deepcopy(baseline_transform)\n",
    "    transform.transforms.insert(0, Augmentation2(policy[key]))\n",
    "    policy_transforms[key] = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy_transforms['Rotatem30'].transforms[0].policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "policy_datasets = {}\n",
    "for key, value in policy_transforms.items():\n",
    "    policy_datasets[key] = CIFAR10_mod(root=dataroot, train=True, download=True, transform=policy_transforms[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_dataloader = torch.utils.data.DataLoader(basic_dataset, batch_size=16, shuffle=False, num_workers=0, drop_last=False)\n",
    "policy_dataloaders = {}\n",
    "for key, value in policy_datasets.items():\n",
    "    policy_dataloaders[key] = torch.utils.data.DataLoader(\n",
    "        policy_datasets[key], batch_size=16, shuffle=False, \n",
    "        num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/3125 [00:01<55:53,  1.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(1., device='cuda:0') top5 tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1004/3125 [00:52<01:49, 19.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.8125, device='cuda:0') top5 tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2004/3125 [01:43<00:57, 19.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.9375, device='cuda:0') top5 tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 3004/3125 [02:34<00:06, 19.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.8750, device='cuda:0') top5 tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [02:40<00:00, 19.49it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_embeddings = []\n",
    "all_labels = []\n",
    "all_indices = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    loader = tqdm(basic_dataloader, disable=False)\n",
    "    for i, (data, label, index) in enumerate(loader):\n",
    "        data, label = data.cuda(), label.cuda()\n",
    "        preds, embeddings = model(data)\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.append(label)\n",
    "        all_indices.append(index)\n",
    "        top1, top5 = accuracy(preds, label, (1, 5))\n",
    "        if i%1000==0:\n",
    "            print(\"top1\", top1, \"top5\", top5)\n",
    "    del data, label, index, preds, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avh = AVH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unaugmented_hardness = avh(model=model, embeddings=torch.cat(all_embeddings), \n",
    "                           targets=torch.cat(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unaugmented_hardness = unaugmented_hardness.cpu().numpy()\n",
    "all_indices = torch.cat(all_indices).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = list(zip(*sorted(zip(unaugmented_hardness, all_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = list(combined[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_indices = sorted_indices[0:200]\n",
    "hard_indices = sorted_indices[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(model, dataloader):\n",
    "    all_preds = []\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    all_indices = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loader = tqdm(dataloader, disable=False)\n",
    "        for i, (data, label, index) in enumerate(loader):\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            preds, embeddings = model(data)\n",
    "\n",
    "            all_preds.append(preds)\n",
    "            all_embeddings.append(embeddings)\n",
    "            all_labels.append(label)\n",
    "            all_indices.append(index)\n",
    "            top1, top5 = accuracy(preds, label, (1, 5))\n",
    "            if i%1000==0:\n",
    "                print(\"top1\", top1, \"top5\", top5)\n",
    "        del data, label, index, preds, embeddings\n",
    "    \n",
    "    avh = AVH()\n",
    "    hardness_scores = avh(model=model, embeddings=torch.cat(all_embeddings), \n",
    "                           targets=torch.cat(all_labels))\n",
    "    return hardness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/3125 [00:00<02:07, 24.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.6250, device='cuda:0') top5 tensor(0.9375, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1004/3125 [00:51<01:50, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.5625, device='cuda:0') top5 tensor(0.8750, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2004/3125 [01:42<00:57, 19.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.4375, device='cuda:0') top5 tensor(0.9375, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 3004/3125 [02:32<00:06, 19.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.5625, device='cuda:0') top5 tensor(0.8750, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [02:39<00:00, 19.64it/s]\n",
      "  0%|          | 4/3125 [00:00<02:48, 18.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.5625, device='cuda:0') top5 tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1004/3125 [00:51<01:49, 19.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.6250, device='cuda:0') top5 tensor(0.8750, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2004/3125 [01:42<00:58, 19.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.4375, device='cuda:0') top5 tensor(0.7500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 3004/3125 [02:32<00:06, 19.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.5625, device='cuda:0') top5 tensor(0.8750, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [02:39<00:00, 19.63it/s]\n",
      "  0%|          | 4/3125 [00:00<05:46,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.3125, device='cuda:0') top5 tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1004/3125 [00:51<01:49, 19.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.5000, device='cuda:0') top5 tensor(0.9375, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2004/3125 [01:42<00:58, 19.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.3750, device='cuda:0') top5 tensor(0.6875, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 3004/3125 [02:33<00:06, 19.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.4375, device='cuda:0') top5 tensor(0.9375, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [02:39<00:00, 19.62it/s]\n",
      "  0%|          | 4/3125 [00:00<05:47,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.0625, device='cuda:0') top5 tensor(0.7500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1004/3125 [00:51<01:50, 19.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.3750, device='cuda:0') top5 tensor(0.8125, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2004/3125 [01:42<00:58, 19.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.3750, device='cuda:0') top5 tensor(0.7500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 3004/3125 [02:33<00:06, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.2500, device='cuda:0') top5 tensor(0.7500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [02:39<00:00, 19.62it/s]\n",
      "  0%|          | 4/3125 [00:00<05:46,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.9375, device='cuda:0') top5 tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1004/3125 [00:51<01:50, 19.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.6250, device='cuda:0') top5 tensor(0.9375, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2004/3125 [01:42<00:58, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.6875, device='cuda:0') top5 tensor(0.9375, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 3004/3125 [02:33<00:06, 19.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 tensor(0.6250, device='cuda:0') top5 tensor(0.9375, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [02:39<00:00, 19.61it/s]\n"
     ]
    }
   ],
   "source": [
    "policy_hardness_scores = {}\n",
    "for key, value in policy_dataloaders.items():\n",
    "    policy_hardness_scores[key] = process(model, policy_dataloaders[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(policy_hardness_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_hardness_scores = {}\n",
    "hard_hardness_scores = {}\n",
    "easy_hardness_scores[\"unaugmented\"] = unaugmented_hardness[easy_indices]\n",
    "hard_hardness_scores[\"unaugmented\"] = unaugmented_hardness[hard_indices]\n",
    "for key, value in policy_hardness_scores.items():\n",
    "    easy_hardness_scores[key] = value[easy_indices].cpu().numpy()\n",
    "    hard_hardness_scores[key] = value[hard_indices].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardness_save_dir = save_path.replace('test.pth', 'hardness_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(hardness_save_dir):\n",
    "    os.makedirs(hardness_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardness_save_path = os.path.join(hardness_save_dir, \"exp3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'policy': policy, 'easy_hardness_scores': easy_hardness_scores, \"hard_hardness_scores\": hard_hardness_scores}, hardness_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/efs-cotton/outputs/fast-autoaugment/confs/hardnessaware/wresnet28x10_rcifar-AA-rerun3/hardness_scores/exp3.pt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hardness_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FA",
   "language": "python",
   "name": "fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
